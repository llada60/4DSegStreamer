<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Streaming 4D Panoptic Segmentation via Dual Threads">
  <meta name="keywords" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:type" content="video.other" />
  <title> Streaming 4D Panoptic Segmentation via Dual Threads Track</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="stylesheet" href="./static/css/styles.css"> -->
  <link rel="icon" href="./static/images/icon_2.png">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="assets/js/video_comparison.js"></script>

  <script src="https://polyfill.io/v3/polyfill.js?features=IntersectionObserver"></script>
  <!-- <script src="./static/js/yall.js"></script> -->
  <script>
      yall(
          {
              observeChanges: true
          }
      );
  </script>
  <!-- <script src="./static/js/scripts.js"></script> -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
  <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"></script>
  <script type="module" src="https://unpkg.com/@google/model-viewer@2.0.1/dist/model-viewer.min.js"></script>
  <style>
    .horizontal_line {
        width: 90%;
        height: 5px;
        border-top: 5px dotted black;
        line-height: 80%;
    }

    .line {
        border-bottom: 1px solid rgb(172, 170, 170);
        margin-top: 1px;
        margin-left: 130px;
        width: 80%;
    }
</style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <!-- <img src="./static/images/icon-3.png" alt="logo" style="width: 78px; height: 78px; margin-right: -0px; margin-bottom: -10px;"> -->
            <!-- <img src="./static/images/icon-2-new.png" alt="logo" style="width: 78px; height: 78px; margin-right: -0px; margin-bottom: -10px;"> -->
            <img src="./static/images/icon_2.png" alt="logo" style="width: 60px; height: 78px; margin-right: -3px; margin-bottom: -10px;">
            <span style="color: rgb(100,149,237); font-weight:bold">4DSeg</span><span style="color: rgb(144,238,144); font-weight:bold">Streamer</span>
            <!-- <img src="./static/images/icon-2-new.png" alt="logo" style="width: 78px; height: 78px; margin-right: -0px; margin-bottom: -10px;"> -->
          </h1>
          <h2 class="title is-1 publication-title">
            Streaming 4D Panoptic Segmentation <br> via Dual Threads Track
          </h2>

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block">
              Anonymous Author(s)
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span style="font-weight:bold">Paper under double-blind review</span>
          </div> -->

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://llada60.github.io/">Ling Liu</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="">Jun Tian</a><sup>2*</sup>,</span>
            <span class="author-block">
              <a href="https://ericyi.github.io">Li Yi</a><sup>2,3,4&#8224;</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Institut Polytechnique de Paris,</span>
            <span class="author-block"><sup>2</sup>IIIS, Tsinghua University,</span>
            <span class="author-block"><sup>3</sup>Shanghai Qi Zhi Institute,</span> 
            <span class="author-block"><sup>4</sup>Shanghai AI Lab</span> 
          </div>

          <div class="is-size-5 publication-authors">
            <span style="font-weight:bold">ICCV 2025</span>
          </div>
          <span class="eql-cntrb">
              <small>
                  <sup>*</sup>Equal Contribution
              </small>
          </span>
          <span class="eql-cntrb">
              <small>
                  <sup>&#8224;</sup>Corresponding Author
              </small>
          </span>


          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/llada60/4DSegStreamer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-slideshare"></i>
                  </span>
                  <span>Slides</span>
                </a>
              </span> -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa fa-database" aria-hidden="true"></i>
                  </span>
                  <span>Supp</span>
                </a>
              </span> -->
            </div>
          </div>

  

        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" class="lazy" poster="./static/images/teaser.png"  autoplay muted loop height="100%">
        <source src="static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <!-- <img src="./static/images/mainpicture.png" alt="logo""> -->
      <h2 class="subtitle has-text-centered">
        <span style="color: rgb(100,149,237); font-weight:bold">4DSeg</span><span style="color: rgb(144,238,144); font-weight:bold">Streamer</span> is a real-time dual-thread framework for fine-grained <span style="color: rgb(100,149,237); font-weight:bold">4D panoptic segmentation</span> in highly dynamic environments. Designed for <span style="color: rgb(144,238,144); font-weight:bold"">online streaming inputs considering computational latency</span>, it achieves a balanced trade-off between accuracy and efficiency. The framework is general and can empower existing 3D and 4D segmentation methods with real-time perception capabilities.  
It also demonstrates superior robustness compared to existing streaming perception approaches, particularly under high-FPS conditions.
      </h2>
    </div>
  </div>
</section>




<section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3"><span style="color: rgb(0, 0, 0); font-weight:bold">Abstract</span></h2>
          <div class="content has-text-justified">
            <p>
              4D panoptic segmentation in a streaming setting is critical for highly dynamic environments, such as evacuating dense crowds and autonomous driving in complex scenarios, where real-time, fine-grained perception within a constrained time budget is essential. In this paper, we introduce 4DSegStreamer, a novel framework that employs a Dual-Thread System to efficiently process streaming frames.  The framework is general and can be seamlessly integrated into existing 3D and 4D segmentation methods to enable real-time capability. It also demonstrates superior robustness compared to existing streaming perception approaches, particularly under high FPS conditions. The system consists of a predictive thread and an inference thread. The predictive thread leverages historical motion and geometric information to extract features and forecast future dynamics. The inference thread ensures timely prediction for incoming frames by aligning with the latest memory and compensating for ego-motion and dynamic object movements. We evaluate 4DSegStreamer on the indoor HOI4D dataset and the outdoor SemanticKITTI and nuScenes datasets. Comprehensive experiments demonstrate the effectiveness of our approach, particularly in accurately predicting dynamic objects in complex scenes.
            </p>
          </div>
        </div>
      </div>

      <!-- Paper video. -->
      <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3"><span style="color: rgb(0, 0, 0); font-weight:bold">Video</span></h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/zru1Z-DaiWE"
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div> -->
          

        </div>
      </div>
    </div>
</section>

<!-- Methods -->
<section class="section">
    <div class="container is-max-widescreen">
      <!-- Pipeline. -->
      <h2 class="title is-3">Dual-thread System</h2>
      <video id="teaser" class="lazy" poster="./static/images/mainpicture.png"  autoplay muted loop height="100%">
        <source src="static/videos/main.mp4"
                type="video/mp4">
      </video>
      
      <div class="columns">
        <div class="column">
          <p>
            The dual-thread system consists of a predictive thread and an inference thread, enabling real-time query for unseen future frames. The <span style="color: rgb(125, 166, 224);font-weight:bold">predictive thread</span> updates the geometric and motion memories with the latest extracted feature and leverages the historical information to forecast future dynamics. The <span style="color: rgb(255, 153, 153);font-weight:bold">inference thread</span> retrieves per-point predictions by geometrically aligning them with the current memory using ego-pose and dynamic object alignment.
          </p>
        </div>
      </div>
    </div>
</section>

<section class="section">
    <div class="container is-max-widescreen">
      <!-- Motion Alignment. -->
      <h2 class="title is-3">Inference Thread: Motion Alignment</h2>
      <video id="teaser" class="lazy" poster="./static/images/alignment_new7.png"  autoplay muted loop height="100%">
        <source src="static/videos/motion_align.mp4"
                type="video/mp4">
      </video>
      
      <div class="columns">
        <div class="column">
          <p>
            In the inference thread, we perform ego-pose alignment and dynamic object alignment to align the current querying frame with the latest memory, which has been updated by previously processed frames. The <span style="color: rgb(144,238,144);font-weight:bold">green points</span> represent the previously processed frame that has been used to update the memory and the <span style="color: rgb(100,149,237);font-weight:bold">blue points</span> are the current querying frame. The <span style="color: rgb(255,212,97);font-weight:bold">yellow box</span> highlights static objects that can be aligned through ego-pose alignment. The <span style="color: rgb(186,79,26);font-weight:bold">red box</span> indicates dynamic objects, which require dynamic object alignment to achieve proper alignment.
          </p>
        </div>
      </div>
    </div>
</section>

<!-- Experiments -->

<section class="section">
    <div class="container is-max-widescreen">
      <h2 class="title is-3">Results</h2>      
      <!-- Roubust. -->
      <h3 class="title is-4">Different FPS Settings</h3>

      <img src="./static/images/Figure_3.png" style="height: 300px; display: block; margin: 0 auto;" >
      
      <div class="columns">
        <div class="column">
          <p>
            Comparison of streaming performance at different FPS settings on the SemanticKITTI dataset.  Our 4DSegStreamer demonstrates significant performance gains and exhibits a slower performance decline as the FPS increases, indicating its robustness as a more advanced 4D streaming system for panoptic segmentation tasks, particularly in high-FPS scenarios.
          </p>
        </div>
      </div>
    </div>
</section>

<section class="section">
    <div class="container is-max-widescreen">
      <!-- General. -->
      <h3 class="title is-4">General Evaluation</h3>
      
      <img src="./static/images/general.png" alt="logo" style="width: 500px; display: block; margin: 0 auto;" >
      
      <div class="columns">
        <div class="column">
          <p>
            Our method is designed as a plug-and-play module to enhance 3D and 4D segmentation backbones, enabling real-time performance in streaming scenarios. Existing 3D and 4D segmentation methods can be easily integrated with our dual-thread system to achieve real-time capabilities. The results demonstrate that our method significantly improves the performance of these backbones in the streaming setting.
          </p>
        </div>
      </div>
    </div>
</section>
<section class="section">
    <div class="container is-max-widescreen">
      <!-- Outdoor dataset. -->
      <h3 class="title is-4">Outdoor Datasets: SemanticKITTI and nuScenes</h3>

      <div class="columns">
        <div class="column">
          <p>
            Depending on whether the camera pose is available, we define two settings:
          </p>
          <ul style="list-style: disc; padding-left: 20px;">
            <li><em><b>Known pose setting</b></em>: we directly use the relative pose to align future frames with the feature memory coordinates.</li>
            <li><em><b>Unknown pose setting</b></em>: we utilize the pose estimated by <a href="https://arxiv.org/abs/2105.11320" target="_blank" rel="noopener noreferrer">Suma++</a> between key frames to update the ego-motion memory, and then use the ego-pose forecaster to propagate the future ego-pose motion, ensuring proper alignment and eliminating ego motion.</li>
          </ul>
        </div>
      </div>


      <img src="./static/images/sk_p.png" alt="logo" style="width: 900px; display: block; margin: 0 auto;" >

      <!-- add a video here -->

      <img src="./static/images/nuscenes1.png" alt="logo" style="width: 1000px; display: block; margin: 0 auto;" >
    </div>
</section>
<section class="section">
    <div class="container is-max-widescreen">
      <!-- Indoor dataset. -->
       <h3 class="title is-4">Indoor Dataset: HOI4D</h3>
       <img src="./static/images/hoi4d.png" alt="logo" style="width: 650px; display: block; margin: 0 auto;" >
    </div>
</section>
<section class="section">
    <div class="container is-max-widescreen">
       <!-- Ablation study. -->
       <h3 class="title is-4">Ablation Study: effects of components</h3>
       <img src="./static/images/ablation.png" alt="logo" style="width: 900px; display: block; margin: 0 auto;" >
    </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="./static/pdfs/paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link"
         href="./static/videos/video-2.mp4">
        <i class="fab fa-youtube"></i>
      </a> -->
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. We thank authors for their codebase.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
</body>
</html>
